

\begin{abstract}
We explore image analogies applied to stereoscopic data synthesis by leveraging an external source of stereo data instead of estimating scene motion or using geometric cues to infer depth / disparity.
We provide a framework to work with a large database of such image or video streams and provide hindsights on disparity computation given our findings.
\end{abstract}